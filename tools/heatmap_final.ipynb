{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "os.environ[\"FLAGS_allocator_strategy\"] = 'auto_growth'\n",
    "\n",
    "import paddle\n",
    "\n",
    "from ppocr.data import create_operators, transform\n",
    "from ppocr.modeling.architectures import build_model\n",
    "from ppocr.postprocess import build_post_process\n",
    "from ppocr.utils.save_load import load_model\n",
    "from ppocr.utils.utility import get_image_file_list\n",
    "import tools.program as program\n",
    "from Visualizer.visualizer import get_local\n",
    "\n",
    "from sys import argv\n",
    "#查看当前的argv列表\n",
    " \n",
    "#也可以添加新的参数\n",
    "argv[1]='-c'\n",
    "if len(argv) <= 2:\n",
    "    argv.append('./configs/rec/rec_cloformer_cppd.yml')\n",
    "else:\n",
    "    argv[2]='./configs/rec/rec_cloformer_cppd.yml'\n",
    "if len(argv) > 3:\n",
    "    del argv[3:]\n",
    "print(argv)\n",
    "\n",
    "get_local.clear()\n",
    "get_local.activate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.transforms as T\n",
    "# from timm.models.vision_transformer import vit_small_patch16_224\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_show(to_shows, cols):\n",
    "    rows = (len(to_shows)-1) // cols + 1\n",
    "    it = iter(to_shows)\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(rows*8.5, cols*2))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            try:\n",
    "                image, title = next(it)\n",
    "            except StopIteration:\n",
    "                image = np.zeros_like(to_shows[0][0])\n",
    "                title = 'pad'\n",
    "            axs[i, j].imshow(image)\n",
    "            axs[i, j].set_title(title)\n",
    "            axs[i, j].set_yticks([])\n",
    "            axs[i, j].set_xticks([])\n",
    "    plt.show()\n",
    "\n",
    "def visualize_head(att_map):\n",
    "    ax = plt.gca()\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(att_map)\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_heads(att_map, cols):\n",
    "    to_shows = []\n",
    "    att_map = att_map.squeeze()\n",
    "    for i in range(att_map.shape[0]):\n",
    "        to_shows.append((att_map[i], f'Head {i}'))\n",
    "    average_att_map = att_map.mean(axis=0)\n",
    "    to_shows.append((average_att_map, 'Head Average'))\n",
    "    grid_show(to_shows, cols=cols)\n",
    "\n",
    "def gray2rgb(image):\n",
    "    return np.repeat(image[...,np.newaxis],3,2)\n",
    "    \n",
    "def cls_padding(image, mask, cls_weight, grid_size):\n",
    "    if not isinstance(grid_size, tuple):\n",
    "        grid_size = (grid_size, grid_size)\n",
    "        \n",
    "    image = np.array(image)\n",
    "\n",
    "    H, W = image.shape[:2]\n",
    "    delta_H = int(H/grid_size[0])\n",
    "    delta_W = int(W/grid_size[1])\n",
    "    \n",
    "    padding_w = delta_W\n",
    "    padding_h = H\n",
    "    padding = np.ones_like(image) * 255\n",
    "    padding = padding[:padding_h, :padding_w]\n",
    "    \n",
    "    padded_image = np.hstack((padding,image))\n",
    "    padded_image = Image.fromarray(padded_image)\n",
    "    draw = ImageDraw.Draw(padded_image)\n",
    "    draw.text((int(delta_W/4),int(delta_H/4)),'CLS', fill=(0,0,0)) # PIL.Image.size = (W,H) not (H,W)\n",
    "\n",
    "    mask = mask / max(np.max(mask),cls_weight)\n",
    "    cls_weight = cls_weight / max(np.max(mask),cls_weight)\n",
    "    \n",
    "    if len(padding.shape) == 3:\n",
    "        padding = padding[:,:,0]\n",
    "        padding[:,:] = np.min(mask)\n",
    "    mask_to_pad = np.ones((1,1)) * cls_weight\n",
    "    mask_to_pad = Image.fromarray(mask_to_pad)\n",
    "    mask_to_pad = mask_to_pad.resize((delta_W, delta_H))\n",
    "    mask_to_pad = np.array(mask_to_pad)\n",
    "\n",
    "    padding[:delta_H,  :delta_W] = mask_to_pad\n",
    "    padded_mask = np.hstack((padding, mask))\n",
    "    padded_mask = padded_mask\n",
    "    \n",
    "    meta_mask = np.zeros((padded_mask.shape[0], padded_mask.shape[1],4))\n",
    "    meta_mask[delta_H:,0: delta_W, :] = 1 \n",
    "    \n",
    "    return padded_image, padded_mask, meta_mask\n",
    "    \n",
    "\n",
    "def visualize_grid_to_grid_with_cls(att_map, grid_index, image, grid_size=7, alpha=0.6):\n",
    "    if not isinstance(grid_size, tuple):\n",
    "        grid_size = (7, 9)\n",
    "    \n",
    "    attention_map = att_map[grid_index]\n",
    "    cls_weight = attention_map[0]\n",
    "    \n",
    "    mask = attention_map[1:].reshape(grid_size[0], grid_size[1])\n",
    "    mask = Image.fromarray(mask).resize((image.size))\n",
    "    \n",
    "    padded_image ,padded_mask, meta_mask = cls_padding(image, mask, cls_weight, grid_size)\n",
    "    \n",
    "    if grid_index != 0: # adjust grid_index since we pad our image\n",
    "        grid_index = grid_index + (grid_index-1) // grid_size[1]\n",
    "        \n",
    "    grid_image = highlight_grid(padded_image, [grid_index], (grid_size[0], grid_size[1]+1))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,7))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ax[0].imshow(grid_image)\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(grid_image)\n",
    "    ax[1].imshow(padded_mask, alpha=alpha, cmap='jet')\n",
    "    ax[1].imshow(meta_mask)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "\n",
    "def visualize_grid_to_grid(att_map, grid_index, image, grid_size=8, alpha=0.6):\n",
    "    if not isinstance(grid_size, tuple):\n",
    "        grid_size = (grid_size, grid_size)\n",
    "        # grid_size = (7, 9)\n",
    "    \n",
    "    H,W = att_map.shape\n",
    "    with_cls_token = False\n",
    "      \n",
    "    # grid_image = highlight_grid(image, [grid_index], grid_size)\n",
    "    \n",
    "    mask = att_map[grid_index].reshape(grid_size[0], grid_size[1])\n",
    "    mask = Image.fromarray(mask).resize((image.size))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,7))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(image)\n",
    "    ax[1].imshow(mask/np.max(mask), alpha=alpha, cmap='jet')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def highlight_grid(image, grid_indexes, grid_size=14):\n",
    "    if not isinstance(grid_size, tuple):\n",
    "        grid_size = (grid_size, grid_size)\n",
    "    \n",
    "    W, H = image.size\n",
    "    h = H / grid_size[0]\n",
    "    w = W / grid_size[1]\n",
    "    image = image.copy()\n",
    "    for grid_index in grid_indexes:\n",
    "        x, y = np.unravel_index(grid_index, (grid_size[0], grid_size[1]))\n",
    "        a= ImageDraw.ImageDraw(image)\n",
    "        a.rectangle([(y*w,x*h),(y*w+w,x*h+h)],fill =None,outline ='red',width =2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global_config = config['Global']\n",
    "\n",
    "    # build post process\n",
    "    post_process_class = build_post_process(config['PostProcess'],\n",
    "                                            global_config)\n",
    "\n",
    "    # build model\n",
    "    if hasattr(post_process_class, 'character'):\n",
    "        char_num = len(getattr(post_process_class, 'character'))\n",
    "        if config[\"Architecture\"][\"algorithm\"] in [\"Distillation\",\n",
    "                                                   ]:  # distillation model\n",
    "            for key in config[\"Architecture\"][\"Models\"]:\n",
    "                if config[\"Architecture\"][\"Models\"][key][\"Head\"][\n",
    "                        \"name\"] == 'MultiHead':  # multi head\n",
    "                    out_channels_list = {}\n",
    "                    if config['PostProcess'][\n",
    "                            'name'] == 'DistillationSARLabelDecode':\n",
    "                        char_num = char_num - 2\n",
    "                    if config['PostProcess'][\n",
    "                            'name'] == 'DistillationNRTRLabelDecode':\n",
    "                        char_num = char_num - 3\n",
    "                    out_channels_list['CTCLabelDecode'] = char_num\n",
    "                    out_channels_list['SARLabelDecode'] = char_num + 2\n",
    "                    out_channels_list['NRTRLabelDecode'] = char_num + 3\n",
    "                    config['Architecture']['Models'][key]['Head'][\n",
    "                        'out_channels_list'] = out_channels_list\n",
    "                else:\n",
    "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n",
    "                        \"out_channels\"] = char_num\n",
    "        elif config['Architecture']['Head'][\n",
    "                'name'] == 'MultiHead':  # multi head\n",
    "            out_channels_list = {}\n",
    "            char_num = len(getattr(post_process_class, 'character'))\n",
    "            if config['PostProcess']['name'] == 'SARLabelDecode':\n",
    "                char_num = char_num - 2\n",
    "            if config['PostProcess']['name'] == 'NRTRLabelDecode':\n",
    "                char_num = char_num - 3\n",
    "            out_channels_list['CTCLabelDecode'] = char_num\n",
    "            out_channels_list['SARLabelDecode'] = char_num + 2\n",
    "            out_channels_list['NRTRLabelDecode'] = char_num + 3\n",
    "            config['Architecture']['Head'][\n",
    "                'out_channels_list'] = out_channels_list\n",
    "        else:  # base rec model\n",
    "            config[\"Architecture\"][\"Head\"][\"out_channels\"] = char_num\n",
    "    model = build_model(config['Architecture'])\n",
    "\n",
    "    load_model(config, model)\n",
    "\n",
    "    # create data ops\n",
    "    transforms = []\n",
    "    for op in config['Eval']['dataset']['transforms']:\n",
    "        op_name = list(op)[0]\n",
    "        if 'Label' in op_name:\n",
    "            continue\n",
    "        elif op_name in ['RecResizeImg']:\n",
    "            op[op_name]['infer_mode'] = True\n",
    "        elif op_name == 'KeepKeys':\n",
    "            if config['Architecture']['algorithm'] == \"SRN\":\n",
    "                op[op_name]['keep_keys'] = [\n",
    "                    'image', 'encoder_word_pos', 'gsrm_word_pos',\n",
    "                    'gsrm_slf_attn_bias1', 'gsrm_slf_attn_bias2'\n",
    "                ]\n",
    "            elif config['Architecture']['algorithm'] == \"SAR\":\n",
    "                op[op_name]['keep_keys'] = ['image', 'valid_ratio']\n",
    "            elif config['Architecture']['algorithm'] == \"RobustScanner\":\n",
    "                op[op_name][\n",
    "                    'keep_keys'] = ['image', 'valid_ratio', 'word_positons']\n",
    "            else:\n",
    "                op[op_name]['keep_keys'] = ['image']\n",
    "        transforms.append(op)\n",
    "    global_config['infer_mode'] = True\n",
    "    ops = create_operators(transforms, global_config)\n",
    "\n",
    "    save_res_path = config['Global'].get('save_res_path',\n",
    "                                         \"./output/rec/predicts_rec.txt\")\n",
    "    if not os.path.exists(os.path.dirname(save_res_path)):\n",
    "        os.makedirs(os.path.dirname(save_res_path))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    infer_imgs = config['Global']['infer_img']\n",
    "    infer_list = config['Global'].get('infer_list', None)\n",
    "    with open(save_res_path, \"w\") as fout:\n",
    "        for file in get_image_file_list(infer_imgs, infer_list=infer_list):\n",
    "            logger.info(\"infer_img: {}\".format(file))\n",
    "            with open(file, 'rb') as f:\n",
    "                img = f.read()\n",
    "                data = {'image': img}\n",
    "            batch = transform(data, ops)\n",
    "            if config['Architecture']['algorithm'] == \"SRN\":\n",
    "                encoder_word_pos_list = np.expand_dims(batch[1], axis=0)\n",
    "                gsrm_word_pos_list = np.expand_dims(batch[2], axis=0)\n",
    "                gsrm_slf_attn_bias1_list = np.expand_dims(batch[3], axis=0)\n",
    "                gsrm_slf_attn_bias2_list = np.expand_dims(batch[4], axis=0)\n",
    "\n",
    "                others = [\n",
    "                    paddle.to_tensor(encoder_word_pos_list),\n",
    "                    paddle.to_tensor(gsrm_word_pos_list),\n",
    "                    paddle.to_tensor(gsrm_slf_attn_bias1_list),\n",
    "                    paddle.to_tensor(gsrm_slf_attn_bias2_list)\n",
    "                ]\n",
    "            if config['Architecture']['algorithm'] == \"SAR\":\n",
    "                valid_ratio = np.expand_dims(batch[-1], axis=0)\n",
    "                img_metas = [paddle.to_tensor(valid_ratio)]\n",
    "            if config['Architecture']['algorithm'] == \"RobustScanner\":\n",
    "                valid_ratio = np.expand_dims(batch[1], axis=0)\n",
    "                word_positons = np.expand_dims(batch[2], axis=0)\n",
    "                img_metas = [\n",
    "                    paddle.to_tensor(valid_ratio),\n",
    "                    paddle.to_tensor(word_positons),\n",
    "                ]\n",
    "            if config['Architecture']['algorithm'] == \"CAN\":\n",
    "                image_mask = paddle.ones(\n",
    "                    (np.expand_dims(\n",
    "                        batch[0], axis=0).shape), dtype='float32')\n",
    "                label = paddle.ones((1, 36), dtype='int64')\n",
    "            images = np.expand_dims(batch[0], axis=0)\n",
    "            images = paddle.to_tensor(images)\n",
    "            if config['Architecture']['algorithm'] == \"SRN\":\n",
    "                preds = model(images, others)\n",
    "            elif config['Architecture']['algorithm'] == \"SAR\":\n",
    "                preds = model(images, img_metas)\n",
    "            elif config['Architecture']['algorithm'] == \"RobustScanner\":\n",
    "                preds = model(images, img_metas)\n",
    "            elif config['Architecture']['algorithm'] == \"CAN\":\n",
    "                preds = model([images, image_mask, label])\n",
    "            else:\n",
    "                preds = model(images)\n",
    "            post_result = post_process_class(preds)\n",
    "            info = None\n",
    "            if isinstance(post_result, dict):\n",
    "                rec_info = dict()\n",
    "                for key in post_result:\n",
    "                    if len(post_result[key][0]) >= 2:\n",
    "                        rec_info[key] = {\n",
    "                            \"label\": post_result[key][0][0],\n",
    "                            \"score\": float(post_result[key][0][1]),\n",
    "                        }\n",
    "                info = json.dumps(rec_info, ensure_ascii=False)\n",
    "            elif isinstance(post_result, list) and isinstance(post_result[0],\n",
    "                                                              int):\n",
    "                # for RFLearning CNT branch \n",
    "                info = str(post_result[0])\n",
    "            else:\n",
    "                if len(post_result[0]) >= 2:\n",
    "                    info = post_result[0][0] + \"\\t\" + str(post_result[0][1])\n",
    "\n",
    "            if info is not None:\n",
    "                logger.info(\"\\t result: {}\".format(info))\n",
    "                fout.write(file + \"\\t\" + info + \"\\n\")\n",
    "    logger.info(\"success!\")\n",
    "    \n",
    "config, device, logger, vdl_writer = program.preprocess()\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./train_data/common_benchmarks/CUTE80/imgs/cute_226.jpg')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = get_local.cache\n",
    "print(list(cache.keys()))\n",
    "attention_maps = cache['EdgeDecoderLayer.forward']\n",
    "print(len(attention_maps))\n",
    "attention_maps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_grid_to_grid_with_cls(attention_maps[0][0,1,:,:], 2, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_grid_to_grid(attention_maps[0][0,5,:,:], 1, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_head(attention_maps[0][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attention_maps[3][0,0].shape)\n",
    "visualize_head(attention_maps[3][0,0].transpose((1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_heads(attention_maps[2], cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_heads(attention_maps[3], cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# 假设attn是你已经提取的注意力图，shape为(num_heads, height, width)\n",
    "# 假设original_image是一个PIL图像或者一个numpy数组\n",
    "\n",
    "# 此函数将归一化和重塑注意力图以匹配原图大小\n",
    "def resize_attention(attn, target_size):\n",
    "    # 假设attn是一个平均化的注意力图\n",
    "    attn = attn.mean(0)  # 取所有头的平均值，如果你想要可视化特定的头，可以单独提取\n",
    "    attn = attn - attn.min()  # Min-max normalization\n",
    "    attn = attn / attn.max()\n",
    "    attn = Image.fromarray(attn)  # 转换为PIL图像以便调整大小\n",
    "    attn = attn.resize(target_size, Image.BILINEAR)  # 重置大小\n",
    "    attn = np.asarray(attn)  # 转换回numpy数组\n",
    "    return attn\n",
    "\n",
    "# 将注意力图调整至原图大小\n",
    "attn = resize_attention(attention_maps[0][0][0], image.size)\n",
    "\n",
    "# 转换原图为numpy数组\n",
    "image = Image.open('./train_data/common_benchmarks/CUTE80/imgs/cute_226.jpg')\n",
    "original_image = np.array(image)\n",
    "\n",
    "# 创建一个与原图大小相同的彩色热图\n",
    "heatmap = plt.get_cmap('jet')(attn)[:, :, :3]  # 获取RGB颜色\n",
    "heatmap = (heatmap * 255).astype(np.uint8)  # 将颜色值范围调整到0-255\n",
    "\n",
    "# 将热图以一定透明度叠加到原图上\n",
    "alpha = 0.6  # 设置热图的透明度\n",
    "overlay = cv2.addWeighted(original_image, alpha, heatmap, 1 - alpha, 0)\n",
    "\n",
    "# 显示叠加图\n",
    "plt.imshow(overlay)\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 此函数将归一化和重塑注意力图以匹配原图大小\n",
    "def resize_attention(attn, target_size):\n",
    "    # 假设attn是一个平均化的注意力图\n",
    "    attn = attn.mean(0)  # 取所有头的平均值，如果你想要可视化特定的头，可以单独提取\n",
    "    attn = attn - attn.min()  # Min-max normalization\n",
    "    attn = attn / attn.max()\n",
    "    attn = Image.fromarray(attn)  # 转换为PIL图像以便调整大小\n",
    "    attn = attn.resize(target_size, Image.BILINEAR)  # 重置大小\n",
    "    attn = np.asarray(attn)  # 转换回numpy数组\n",
    "    return attn\n",
    "\n",
    "def visual_att(head, img_file, save_file):\n",
    "    cache = get_local.cache\n",
    "    attention_maps = cache['EdgeDecoderLayer.forward']\n",
    "    map_0 = attention_maps[0]\n",
    "    map_0 = map_0.reshape((1, 12, 26, 2, 32))\n",
    "    heatmap = map_0.squeeze()\n",
    "\n",
    "    image = Image.open(img_file)\n",
    "    original_image = np.array(image).transpose(1,0,2)\n",
    "\n",
    "    maps = []\n",
    "    for i in range(0,16):\n",
    "        # print(i)\n",
    "        H,W = image.size\n",
    "        #! -----------\n",
    "        #! config head\n",
    "        #! -----------\n",
    "        attn = resize_attention(heatmap[head][int(i)], (W,H))\n",
    "        # print(attn.shape)\n",
    "\n",
    "        # 创建一个与原图大小相同的彩色热图\n",
    "        heatmap_i = plt.get_cmap('jet')(attn)[:, :, :3]  # 获取RGB颜色\n",
    "        heatmap_i = (heatmap_i * 255).astype(np.uint8)  # 将颜色值范围调整到0-255\n",
    "        # print(heatmap_i.shape)\n",
    "\n",
    "        # 将热图以一定透明度叠加到原图上\n",
    "        alpha = 0.6  # 设置热图的透明度\n",
    "        overlay = cv2.addWeighted(original_image, alpha, heatmap_i, 1 - alpha, 0)\n",
    "        overlay = overlay.transpose(1,0,2)\n",
    "        maps.append(overlay)\n",
    "        dir_name, filename = os.path.split(save_file)\n",
    "        sub_img_path = os.path.join(dir_name, 'sub_img', filename)\n",
    "        path, extension = sub_img_path.rsplit('.', 1)\n",
    "        print(\"{}_{}.{}\".format(path, i, extension))\n",
    "        plt.imsave(\"{}_{}.{}\".format(path, i, extension), overlay)\n",
    "    # 计算子图的布局，你可以根据图像数量和期望的布局调整这里的参数\n",
    "    nrows = int(np.ceil(len(maps) ** 0.5))\n",
    "    ncols = int(np.ceil(len(maps) / nrows))\n",
    "\n",
    "    # 创建一个大图和多个子图\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(ncols * 3, nrows * 3))\n",
    "\n",
    "    # 遍历所有的子图并在每个子图中显示图像\n",
    "    for ax, img in zip(axs.flatten(), maps):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')  # 不显示坐标轴\n",
    "\n",
    "    # 如果图片数量不是完全填满子图，隐藏多余的子图\n",
    "    for ax in axs.flatten()[len(maps):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    # 调整子图间距\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CUTE80'\n",
    "img_path = './train_data/common_benchmarks/{}/imgs/'.format(dataset)\n",
    "save_path = './output/rec/visiual/'\n",
    "head = 11\n",
    "img = 'cute_124.jpg'\n",
    "img_file = os.path.join(img_path, img)\n",
    "save_file = os.path.join(save_path, '{}_h{}'.format(dataset, head), img)\n",
    "os.makedirs(os.path.join(save_path, '{}_h{}'.format(dataset, head), 'sub_img'), exist_ok=True)\n",
    "\n",
    "visual_att(head, img_file, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output/rec/visiual/CUTE80_h3/sub_img/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CUTE80'\n",
    "img_path = './train_data/common_benchmarks/{}/imgs/'.format(dataset)\n",
    "save_path = './output/rec/visiual/'\n",
    "head = 3\n",
    "img_name = os.listdir(img_path)\n",
    "\n",
    "for img in img_name:\n",
    "    img_file = os.path.join(img_path, img)\n",
    "    os.makedirs(os.path.join(save_path, '{}_h{}'.format(dataset, head), 'sub_img'), exist_ok=True)\n",
    "    save_file = os.path.join(save_path, '{}_h{}'.format(dataset, head), img)\n",
    "    while len(argv) <=5:\n",
    "        argv.append('')\n",
    "    \n",
    "    argv[1]='-c'\n",
    "    argv[2]='./configs/rec/rec_cloformer_cppd.yml'\n",
    "    argv[3]='-o'\n",
    "    argv[4]='Global.infer_img={}'.format(img_file)        \n",
    "    \n",
    "    if len(argv) > 5:\n",
    "        del argv[5:]\n",
    "        \n",
    "    get_local.clear()\n",
    "    get_local.activate()\n",
    "    \n",
    "    config, device, logger, vdl_writer = program.preprocess()\n",
    "    main()\n",
    "    visual_att(head, img_file, save_file)\n",
    "\n",
    "    print(img_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
